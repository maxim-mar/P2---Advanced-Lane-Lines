{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Computer Vision\n",
    "\n",
    "## Project Steps\n",
    "\n",
    "Steps we’ve covered so far:\n",
    "\n",
    "    Camera calibration\n",
    "    Distortion correction\n",
    "    Color/gradient threshold\n",
    "    Perspective transform\n",
    "After doing these steps, you’ll be given two additional steps for the project:\n",
    "\n",
    "    Detect lane lines\n",
    "    Determine the lane curvature\n",
    "    \n",
    "## Processing Each Image\n",
    "In the project at the end of this module, the first thing you'll do is to compute the camera calibration matrix and distortion coefficients. You only need to compute these once, and then you'll apply them to undistort each new frame. Next, you'll apply thresholds to create a binary image and then apply a perspective transform.\n",
    "\n",
    "### Thresholding\n",
    "You'll want to try out various combinations of color and gradient thresholds to generate a binary image where the lane lines are clearly visible. There's more than one way to achieve a good result, but for example, given the image above, the output you're going for should look something like this:\n",
    "![](https://video.udacity-data.com/topher/2016/December/58421f8f_binary-combo-img/binary-combo-img.jpg)\n",
    "\n",
    "### Perspective Transform\n",
    "Next, you want to identify four source points for your perspective transform. In this case, you can assume the road is a flat plane. This isn't strictly true, but it can serve as an approximation for this project. You would like to pick four points in a trapezoidal shape (similar to region masking) that would represent a rectangle when looking down on the road from above.\n",
    "\n",
    "The easiest way to do this is to investigate an image where the lane lines are straight, and find four points lying along the lines that, after perspective transform, make the lines look straight and vertical from a bird's eye view perspective.\n",
    "\n",
    "![](https://video.udacity-data.com/topher/2016/December/58448557_warped-straight-lines/warped-straight-lines.jpg)\n",
    "\n",
    "### Now for curved lines\n",
    "Those same four source points will now work to transform any image (again, under the assumption that the road is flat and the camera perspective hasn't changed). When applying the transform to new images, the test of whether or not you got the transform correct, is that the lane lines should appear parallel in the warped images, whether they are straight or curved.\n",
    "\n",
    "Here's an example of applying a perspective transform to your thresholded binary image, using the same source and destination points as above, showing that the curved lines are (more or less) parallel in the transformed image:\n",
    "![](https://video.udacity-data.com/topher/2016/December/5844911a_warped-curved-lines/warped-curved-lines.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the Lane Lines\n",
    "You now have a thresholded warped image and you're ready to map out the lane lines! There are many ways you could go about this, but here's one example of how you might do it:\n",
    "\n",
    "![](https://video.udacity-data.com/topher/2016/December/58422552_warped-example/warped-example.jpg)\n",
    "\n",
    "### Line Finding Method: Peaks in a Histogram\n",
    "\n",
    "After applying calibration, thresholding, and a perspective transform to a road image, you should have a binary image where the lane lines stand out clearly. However, you still need to decide explicitly which pixels are part of the lines and which belong to the left line and which belong to the right line.\n",
    "\n",
    "Plotting a histogram of where the binary activations occur across the image is one potential solution for this. In the quiz below, let's take a couple quick steps to create our histogram!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our image\n",
    "# `mpimg.imread` will load .jpg as 0-255, so normalize back to 0-1\n",
    "img = mpimg.imread('warped_example.jpg')/255\n",
    "\n",
    "def hist(img):\n",
    "    # TO-DO: Grab only the bottom half of the image\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "\n",
    "    # TO-DO: Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "histogram = hist(img)\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window\n",
    "With this histogram we are adding up the pixel values along each column in the image. In our thresholded binary image, pixels are either 0 or 1, so the two most prominent peaks in this histogram will be good indicators of the x-position of the base of the lane lines. We can use that as a starting point for where to search for the lines. From that point, we can use a sliding window, placed around the line centers, to find and follow the lines up to the top of the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Sliding Windows and Fit a Polynomial\n",
    "As shown in the previous animation, we can use the two highest peaks from our histogram as a starting point for determining where the lane lines are, and then use sliding windows moving upward in the image (further along the road) to determine where the lane lines go.\n",
    "\n",
    "### Split the histogram for the two lines\n",
    "The first step we'll take is to split the histogram into two sides, one for each lane line."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have created a warped binary image called \"binary_warped\"\n",
    "# Take a histogram of the bottom half of the image\n",
    "histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "# Create an output image to draw on and visualize the result\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]//2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above, we also create out_img to help with visualizing our output later on.\n",
    "### Set up windows and window hyperparameters\n",
    "Our next step is to set a few hyperparameters related to our sliding windows, and set them up to iterate across the binary activations in the image. We have some base hyperparameters below, but don't forget to try out different values in your own implementation to see what works best!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "\n",
    "# Set height of windows - based on nwindows above and image shape\n",
    "window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "# Identify the x and y positions of all nonzero (i.e. activated) pixels in the image\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "# Current positions to be updated later for each window in nwindows\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through nwindows to track curvature\n",
    "Now that we've set up what the windows look like and have a starting point, we'll want to loop for nwindows, with the given window sliding left or right if it finds the mean position of activated pixels within the window to have shifted.\n",
    "\n",
    "You'll implement this part in the quiz below, but here's a few steps to get you started:\n",
    "\n",
    "### Loop through each window in nwindows\n",
    "Find the boundaries of our current window. This is based on a combination of the current window's starting point (leftx_current and rightx_current), as well as the margin you set in the hyperparameters.\n",
    "Use cv2.rectangle to draw these window boundaries onto our visualization image out_img. This is required for the quiz, but you can skip this step in practice if you don't need to visualize where the windows are.\n",
    "Now that we know the boundaries of our window, find out which activated pixels from nonzeroy and nonzerox above actually fall into the window.\n",
    "Append these to our lists left_lane_inds and right_lane_inds.\n",
    "If the number of pixels you found in Step 4 are greater than your hyperparameter minpix, re-center our window (i.e. leftx_current or rightx_current) based on the mean position of these pixels.\n",
    "Fit a polynomial\n",
    "Now that we have found all our pixels belonging to each line through the sliding window method, it's time to fit a polynomial to the line. First, we have a couple small steps to ready our pixels."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assuming we have `left_fit` and `right_fit` from `np.polyfit` before\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of how we fit the lines above - while normally you calculate a y-value for a given x, here we do the opposite. Why? Because we expect our lane lines to be (mostly) vertically-oriented.\n",
    "### Visualization\n",
    "Once you reach this point, you're done! But here is how you can visualize the result as well:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out_img[lefty, leftx] = [255, 0, 0]\n",
    "out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
